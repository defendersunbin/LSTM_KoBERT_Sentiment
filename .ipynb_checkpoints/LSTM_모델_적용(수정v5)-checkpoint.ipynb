{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ayz1070/CapstoneStockModelingProject/blob/main/LSTM_%EB%AA%A8%EB%8D%B8_%EC%A0%81%EC%9A%A9(%EC%88%98%EC%A0%95v5).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "NpF3gfFjhR0A"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Conv1D, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from tensorflow.keras.losses import Huber\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 77
    },
    "id": "UA_Mw4ijfGMp",
    "outputId": "34199f2c-7ce1-4d67-d4c7-d1b09a54d8c7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zqp-PhrCWHAI",
    "outputId": "97dea91e-cf1e-424a-ee83-a2c0d207a59e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ahn\\anaconda3\\envs\\CapstonStockProject\\lib\\site-packages\\openpyxl\\styles\\stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['삼성전자', 'LG에너지솔루션']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kospi = pd.read_excel(\"kospi100.xlsx\", engine='openpyxl')\n",
    "\n",
    "companies_list = []\n",
    "companies = kospi['종목명'][:2].tolist()\n",
    "companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "2-i7vtCNieta"
   },
   "outputs": [],
   "source": [
    "# sequence_dataset 만들기\n",
    "def make_sequence_dataset(feature, label, window_size):\n",
    "\n",
    "  feature_list = []   # 생성될 feature list\n",
    "  label_list = []     # 생성될 label list\n",
    "\n",
    "  for i in range(len(feature)-window_size): # range는 전체값에서 window_size를 뺀 값\n",
    "\n",
    "    feature_list.append(feature[i:i+window_size]) # feature list 에 i번째서 부터 window size 만큼의 입력데이터를 추가\n",
    "    label_list.append(label[i+window_size]) # label list 에 그 다음 번째('window_size + 1' 번째)의 정답데이터를 추가\n",
    "\n",
    "  return np.array(feature_list), np.array(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "PN-MNYDliuLx"
   },
   "outputs": [],
   "source": [
    "#예측값 저장 dict 만들기\n",
    "\n",
    "day_five = {}\n",
    "day_ten = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f2bf7bb2",
    "outputId": "c2b5bc94-5926-485d-f087-9f1d90d492db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삼성전자 주가 분석중...\n",
      "Epoch 1/100\n",
      "45/45 [==============================] - 2s 12ms/step - loss: 0.1566 - mse: 0.3149\n",
      "Epoch 2/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 0.0467 - mse: 0.0935\n",
      "Epoch 3/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 0.0201 - mse: 0.0403\n",
      "Epoch 4/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 0.0178 - mse: 0.0355\n",
      "Epoch 5/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 0.0164 - mse: 0.0329\n",
      "Epoch 6/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 0.0146 - mse: 0.0293\n",
      "Epoch 7/100\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 0.0126 - mse: 0.0253\n",
      "Epoch 8/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 0.0107 - mse: 0.0214\n",
      "Epoch 9/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 0.0083 - mse: 0.0166\n",
      "Epoch 10/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 0.0049 - mse: 0.0099\n",
      "Epoch 11/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 0.0038 - mse: 0.0076\n",
      "Epoch 12/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 0.0031 - mse: 0.0061\n",
      "Epoch 13/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 0.0025 - mse: 0.0051\n",
      "Epoch 14/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 0.0021 - mse: 0.0042\n",
      "Epoch 15/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 0.0018 - mse: 0.0035\n",
      "Epoch 16/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 0.0015 - mse: 0.0030\n",
      "Epoch 17/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 0.0014 - mse: 0.0027\n",
      "Epoch 18/100\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 0.0012 - mse: 0.0024\n",
      "Epoch 19/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 0.0011 - mse: 0.0022\n",
      "Epoch 20/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 9.9657e-04 - mse: 0.0020\n",
      "Epoch 21/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 8.9863e-04 - mse: 0.0018\n",
      "Epoch 22/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 8.2044e-04 - mse: 0.0016\n",
      "Epoch 23/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 7.6151e-04 - mse: 0.0015\n",
      "Epoch 24/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 6.9519e-04 - mse: 0.0014\n",
      "Epoch 25/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 6.4893e-04 - mse: 0.0013\n",
      "Epoch 26/100\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 5.9419e-04 - mse: 0.0012\n",
      "Epoch 27/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 5.4433e-04 - mse: 0.0011\n",
      "Epoch 28/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 5.0313e-04 - mse: 0.0010\n",
      "Epoch 29/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 4.7378e-04 - mse: 9.4755e-04\n",
      "Epoch 30/100\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 4.4810e-04 - mse: 8.9619e-04\n",
      "Epoch 31/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 4.1903e-04 - mse: 8.3806e-04\n",
      "Epoch 32/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 4.0579e-04 - mse: 8.1158e-04\n",
      "Epoch 33/100\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 3.7865e-04 - mse: 7.5731e-04\n",
      "Epoch 34/100\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 3.7439e-04 - mse: 7.4878e-04\n",
      "Epoch 35/100\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 3.4377e-04 - mse: 6.8754e-04\n",
      "Epoch 36/100\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 3.2755e-04 - mse: 6.5510e-04\n",
      "Epoch 37/100\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 3.1848e-04 - mse: 6.3695e-04\n",
      "Epoch 38/100\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 3.0528e-04 - mse: 6.1057e-04\n",
      "Epoch 39/100\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 2.9287e-04 - mse: 5.8574e-04\n",
      "Epoch 40/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 2.9010e-04 - mse: 5.8021e-04\n",
      "Epoch 41/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 2.7371e-04 - mse: 5.4741e-04\n",
      "Epoch 42/100\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 2.6898e-04 - mse: 5.3796e-04\n",
      "Epoch 43/100\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 2.6484e-04 - mse: 5.2967e-04\n",
      "Epoch 44/100\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 2.6331e-04 - mse: 5.2663e-04\n",
      "Epoch 45/100\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 2.4837e-04 - mse: 4.9674e-04\n",
      "Epoch 46/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 2.5337e-04 - mse: 5.0675e-04\n",
      "Epoch 47/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 2.3846e-04 - mse: 4.7692e-04\n",
      "Epoch 48/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 2.3820e-04 - mse: 4.7640e-04\n",
      "Epoch 49/100\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 2.3343e-04 - mse: 4.6685e-04\n",
      "Epoch 50/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 2.2970e-04 - mse: 4.5941e-04\n",
      "Epoch 51/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 2.3740e-04 - mse: 4.7480e-04\n",
      "Epoch 52/100\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 2.2595e-04 - mse: 4.5190e-04\n",
      "Epoch 53/100\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 2.1923e-04 - mse: 4.3845e-04\n",
      "Epoch 54/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 2.1220e-04 - mse: 4.2440e-04\n",
      "Epoch 55/100\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 2.0920e-04 - mse: 4.1841e-04\n",
      "Epoch 56/100\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 2.1084e-04 - mse: 4.2168e-04\n",
      "Epoch 57/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 2.0606e-04 - mse: 4.1213e-04\n",
      "Epoch 58/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 2.0854e-04 - mse: 4.1707e-04\n",
      "Epoch 59/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 2.0343e-04 - mse: 4.0687e-04\n",
      "Epoch 60/100\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 2.0706e-04 - mse: 4.1412e-04\n",
      "Epoch 61/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 2.0954e-04 - mse: 4.1908e-04\n",
      "Epoch 62/100\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 1.9358e-04 - mse: 3.8716e-04\n",
      "Epoch 63/100\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 2.0215e-04 - mse: 4.0429e-04\n",
      "Epoch 64/100\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 1.8959e-04 - mse: 3.7917e-04\n",
      "Epoch 65/100\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 1.8940e-04 - mse: 3.7881e-04\n",
      "Epoch 66/100\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 1.8917e-04 - mse: 3.7833e-04\n",
      "Epoch 67/100\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 1.8966e-04 - mse: 3.7933e-04\n",
      "Epoch 68/100\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 2.0302e-04 - mse: 4.0605e-04\n",
      "Epoch 69/100\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 1.8350e-04 - mse: 3.6701e-04\n",
      "Epoch 70/100\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 1.8094e-04 - mse: 3.6188e-04\n",
      "Epoch 71/100\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 1.9131e-04 - mse: 3.8263e-04\n",
      "Epoch 72/100\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 1.8398e-04 - mse: 3.6796e-04\n",
      "Epoch 73/100\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 1.8679e-04 - mse: 3.7358e-04\n",
      "Epoch 74/100\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 1.8203e-04 - mse: 3.6406e-04\n",
      "Epoch 75/100\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 1.7383e-04 - mse: 3.4767e-04\n",
      "Epoch 76/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 1.7678e-04 - mse: 3.5357e-04\n",
      "Epoch 77/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 1.9773e-04 - mse: 3.9545e-04\n",
      "Epoch 78/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 1.8495e-04 - mse: 3.6990e-04\n",
      "Epoch 79/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 1.7184e-04 - mse: 3.4368e-04\n",
      "Epoch 80/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 1.7157e-04 - mse: 3.4314e-04\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 1s 12ms/step - loss: 1.7483e-04 - mse: 3.4966e-04\n",
      "Epoch 82/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 1.7329e-04 - mse: 3.4659e-04\n",
      "Epoch 83/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 1.7733e-04 - mse: 3.5467e-04\n",
      "Epoch 84/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 1.7153e-04 - mse: 3.4306e-04\n",
      "Epoch 85/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 1.7204e-04 - mse: 3.4408e-04\n",
      "Epoch 86/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 1.7029e-04 - mse: 3.4059e-04\n",
      "Epoch 87/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 1.6240e-04 - mse: 3.2481e-04\n",
      "Epoch 88/100\n",
      "45/45 [==============================] - 1s 13ms/step - loss: 1.6858e-04 - mse: 3.3715e-04\n",
      "Epoch 89/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 1.6807e-04 - mse: 3.3613e-04\n",
      "Epoch 90/100\n",
      "45/45 [==============================] - 1s 13ms/step - loss: 1.6617e-04 - mse: 3.3234e-04\n",
      "Epoch 91/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 1.5877e-04 - mse: 3.1754e-04\n",
      "Epoch 92/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 1.5455e-04 - mse: 3.0909e-04\n",
      "Epoch 93/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 1.5686e-04 - mse: 3.1373e-04\n",
      "Epoch 94/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 1.7195e-04 - mse: 3.4389e-04\n",
      "Epoch 95/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 1.5745e-04 - mse: 3.1490e-04\n",
      "Epoch 96/100\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 1.5461e-04 - mse: 3.0923e-04\n",
      "Epoch 97/100\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 1.5586e-04 - mse: 3.1171e-04\n",
      "Epoch 98/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 1.5547e-04 - mse: 3.1095e-04\n",
      "Epoch 99/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 1.5631e-04 - mse: 3.1262e-04\n",
      "Epoch 100/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 1.5900e-04 - mse: 3.1801e-04\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "21340\n",
      "91000\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Epoch 1/100\n",
      "45/45 [==============================] - 2s 12ms/step - loss: 0.0597 - mse: 0.1194\n",
      "Epoch 2/100\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 0.0187 - mse: 0.0374\n",
      "Epoch 3/100\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 0.0108 - mse: 0.0217\n",
      "Epoch 4/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 0.0084 - mse: 0.0167\n",
      "Epoch 5/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 0.0062 - mse: 0.0125\n",
      "Epoch 6/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 0.0047 - mse: 0.0094\n",
      "Epoch 7/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 0.0036 - mse: 0.0071\n",
      "Epoch 8/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 0.0027 - mse: 0.0055\n",
      "Epoch 9/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 0.0021 - mse: 0.0043\n",
      "Epoch 10/100\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 0.0017 - mse: 0.0034\n",
      "Epoch 11/100\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 0.0013 - mse: 0.0027\n",
      "Epoch 12/100\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 0.0011 - mse: 0.0022\n",
      "Epoch 13/100\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 8.9045e-04 - mse: 0.0018\n",
      "Epoch 14/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 7.4121e-04 - mse: 0.0015\n",
      "Epoch 15/100\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 6.2883e-04 - mse: 0.0013\n",
      "Epoch 16/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 5.4372e-04 - mse: 0.0011\n",
      "Epoch 17/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 4.8075e-04 - mse: 9.6150e-04\n",
      "Epoch 18/100\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 4.3724e-04 - mse: 8.7447e-04\n",
      "Epoch 19/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 4.0794e-04 - mse: 8.1587e-04\n",
      "Epoch 20/100\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 3.7515e-04 - mse: 7.5030e-04\n",
      "Epoch 21/100\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 3.6727e-04 - mse: 7.3455e-04\n",
      "Epoch 22/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 3.4260e-04 - mse: 6.8521e-04\n",
      "Epoch 23/100\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 3.1736e-04 - mse: 6.3472e-04\n",
      "Epoch 24/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 3.2533e-04 - mse: 6.5067e-04\n",
      "Epoch 25/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 3.0011e-04 - mse: 6.0022e-04\n",
      "Epoch 26/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 2.8308e-04 - mse: 5.6616e-04\n",
      "Epoch 27/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 2.7238e-04 - mse: 5.4476e-04\n",
      "Epoch 28/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 2.6412e-04 - mse: 5.2824e-04\n",
      "Epoch 29/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 2.5695e-04 - mse: 5.1390e-04\n",
      "Epoch 30/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 2.5387e-04 - mse: 5.0774e-04\n",
      "Epoch 31/100\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 2.5606e-04 - mse: 5.1212e-04\n",
      "Epoch 32/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 2.4866e-04 - mse: 4.9732e-04\n",
      "Epoch 33/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 2.5002e-04 - mse: 5.0004e-04\n",
      "Epoch 34/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 2.4328e-04 - mse: 4.8656e-04\n",
      "Epoch 35/100\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 2.4282e-04 - mse: 4.8564e-04\n",
      "Epoch 36/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 2.3291e-04 - mse: 4.6582e-04\n",
      "Epoch 37/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 2.2489e-04 - mse: 4.4977e-04\n",
      "Epoch 38/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 2.3351e-04 - mse: 4.6702e-04\n",
      "Epoch 39/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 2.2800e-04 - mse: 4.5600e-04\n",
      "Epoch 40/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 2.2306e-04 - mse: 4.4613e-04\n",
      "Epoch 41/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 2.1995e-04 - mse: 4.3991e-04\n",
      "Epoch 42/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 2.1738e-04 - mse: 4.3476e-04\n",
      "Epoch 43/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 2.1468e-04 - mse: 4.2937e-04\n",
      "Epoch 44/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 2.1337e-04 - mse: 4.2674e-04\n",
      "Epoch 45/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 2.3258e-04 - mse: 4.6517e-04\n",
      "Epoch 46/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 1.9919e-04 - mse: 3.9837e-04\n",
      "Epoch 47/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 1.9506e-04 - mse: 3.9012e-04\n",
      "Epoch 48/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 2.0424e-04 - mse: 4.0848e-04\n",
      "Epoch 49/100\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 1.9796e-04 - mse: 3.9592e-04\n",
      "Epoch 50/100\n",
      "31/45 [===================>..........] - ETA: 0s - loss: 2.0534e-04 - mse: 4.1067e-04"
     ]
    }
   ],
   "source": [
    "for company in companies:\n",
    " print(company, '주가 분석중...')\n",
    " csv_df = pd.read_csv(f'{company}.csv')  # CSV 파일명 입력\n",
    " csv_df = csv_df.loc[:, ['Date', 'Close', 'BPS', 'EPS', '금리', '환율']]\n",
    " csv_df = csv_df.set_index('Date') # 날짜를 index로 바꿈\n",
    " csv_df.dropna()\n",
    "\n",
    " # 날짜 빼고 정규화 작업 진행 -> MinMaxScaler 사용\n",
    " scaler = MinMaxScaler()\n",
    "\n",
    " # 정규화 수행 -> 정규화된 데이터프레임은 scaled_df\n",
    " scale_cols = ['Close', 'BPS', 'EPS', '금리', '환율']\n",
    " scaled_df = scaler.fit_transform(csv_df[scale_cols]) # 정규화된 데이터는 넘파이 형태\n",
    " scaled_df = pd.DataFrame(scaled_df, columns = scale_cols) # Pandas DataFrame 형태로 변경\n",
    " scaled_csv_df = scaled_df.set_index(csv_df.index)\n",
    "\n",
    " # 입력데이터 -> 이전날까지의 종가와 변수들\n",
    " # 정답데이터 -> 다음날의 종가\n",
    " feature_cols = ['Close', 'BPS', 'EPS', '금리', '환율']\n",
    " label_cols = ['Close']\n",
    "\n",
    " # 입력데이터, 정답데이터 프레임 -> feature_df, label_df\n",
    " feature_df = scaled_csv_df[feature_cols]\n",
    " label_df = scaled_csv_df[label_cols]\n",
    "\n",
    " # DataFrame을 Numpy 형태로 저장\n",
    " feature_np = feature_df.to_numpy()\n",
    " label_np = label_df.to_numpy()\n",
    "\n",
    " window_size = 80  # window_size 만큼의 입력데이터를 이용해 바로 다음 값에 오는 Close 값을 예측\n",
    " X, y = make_sequence_dataset(feature_np, label_np, window_size) # X에는 np.array(feature_list), y에는 np.array(label_list) 가 대입됨\n",
    "\n",
    " # 모델 훈련을 위한 준비 -> 훈련을 하고, 제대로 훈련이 됐는지 테스트\n",
    " split = int(len(X)*0.7) # 테스트 데이터로 분리 -> train:test = 7:3\n",
    "\n",
    " # 훈련data 는 전체 데이터의 70퍼센트\n",
    " X_train = X[0:split]\n",
    " y_train = y[0:split]\n",
    "\n",
    " # 테스트data 는 전체 데이터의 30퍼센트\n",
    " X_test = X[split:]\n",
    " y_test = y[split:]\n",
    "\n",
    " ## 5일 예측\n",
    " #LSTM 모델 구축\n",
    " model = Sequential()\n",
    "\n",
    " # 1차원 feature map 생성\n",
    " model.add(Conv1D(filters=32, kernel_size=5,\n",
    "           padding=\"causal\",\n",
    "           activation=\"relu\",\n",
    "           input_shape=[window_size, 5]))# input_shape = (40,5) -> 다음값 예측을 위한 이전 40개(window_size)의 값과 5개의 특성을 입력으로 넣습니다\n",
    "\n",
    " # LSTM layer\n",
    " model.add(LSTM(units = 16, activation = 'tanh'))\n",
    " model.add(Dense(units = 16, activation = 'sigmoid'))\n",
    " model.add(Dense(units = 5)) # 출력층\n",
    "\n",
    " # 모델 컴파일\n",
    " loss = Huber()\n",
    " optimizer = Adam(0.0005)\n",
    " model.compile(loss=loss, optimizer=optimizer, metrics=['mse']) # 손실 함수는 Huber, 옵티마이저는 Adam,  평가지표는 mse로 설정\n",
    "\n",
    " # 조기종료 설정 -> earlystopping은 10번의 epoch통안 loss 개선이 없다면 학습을 멈춤\n",
    " earlystopping = EarlyStopping(monitor='loss', patience=10)\n",
    "\n",
    "\n",
    " # 모델 학습 -> epoch은 100번 진행\n",
    " model.fit(X_train, y_train, epochs=100, batch_size=32, callbacks=[earlystopping])\n",
    "\n",
    " # 주가 예측 -> test 데이터를 이용하여 학습된 LSTM모델을 테스트\n",
    " predictions = model.predict(X_test)\n",
    "\n",
    " # 실제값 변환\n",
    " # 실제값으로 변화시키기 위해서 기존 데이터에서 종가의 최댓값과 최솟값을 가져옵니다\n",
    " close_min = csv_df['Close'].min()\n",
    " close_max = csv_df['Close'].max()\n",
    "\n",
    " print(csv_df['Close'].min())\n",
    " print(csv_df['Close'].max())\n",
    "\n",
    " # MinMaxScaler이용해서 실제값으로 역변환\n",
    " scaler2 = MinMaxScaler()\n",
    " scaled_df2 = scaler2.fit_transform(csv_df[['Close']])\n",
    "\n",
    " # MinMaxScaler에 정규화에 사용한 최솟값과 최댓값을 설정\n",
    " scaler2.data_min_ = close_min  # 정규화에 사용한 최솟값\n",
    " scaler2.data_max_ = close_max  # 정규화에 사용한 최댓값\n",
    "\n",
    " # 예측한 출력값을 실제값으로 역변환\n",
    " original_pred_values = scaler2.inverse_transform(predictions)\n",
    "\n",
    " # 실제로 에측하기\n",
    " # feature_df 에서 가장 최근의 값을 window_size 만큼 가져옴\n",
    " pred_feature = feature_df.tail(window_size)\n",
    "\n",
    " pred_feature_list = []\n",
    " pred_feature_list.append(pred_feature)\n",
    " pred_feature = np.array(pred_feature_list)\n",
    "\n",
    " # 5일 예측 -> 5일까지의 예측값 5개 출력\n",
    " predictions_5d = model.predict(pred_feature)\n",
    " pred_values_5d = scaler2.inverse_transform(predictions_5d)\n",
    "\n",
    "\n",
    " ##10일 예측\n",
    " #LSTM 모델 구축\n",
    " model = Sequential()\n",
    "\n",
    " # 1차원 feature map 생성\n",
    " model.add(Conv1D(filters=32, kernel_size=5,\n",
    "           padding=\"causal\",\n",
    "           activation=\"relu\",\n",
    "           input_shape=[window_size, 5]))# input_shape = (40,5) -> 다음값 예측을 위한 이전 40개(window_size)의 값과 5개의 특성을 입력으로 넣습니다\n",
    "\n",
    " # LSTM layer\n",
    " model.add(LSTM(units = 16, activation = 'tanh'))\n",
    " model.add(Dense(units = 16, activation = 'sigmoid'))\n",
    " model.add(Dense(units = 10)) # 출력층\n",
    "\n",
    "  # 모델 컴파일\n",
    " loss = Huber()\n",
    " optimizer = Adam(0.0005)\n",
    " model.compile(loss=loss, optimizer=optimizer, metrics=['mse']) # 손실 함수는 Huber, 옵티마이저는 Adam,  평가지표는 mse로 설정\n",
    "\n",
    " # 조기종료 설정 -> earlystopping은 10번의 epoch통안 loss 개선이 없다면 학습을 멈춤\n",
    " earlystopping = EarlyStopping(monitor='loss', patience=10)\n",
    "\n",
    "\n",
    " # 모델 학습 -> epoch은 100번 진행\n",
    " model.fit(X_train, y_train, epochs=100, batch_size=32, callbacks=[earlystopping])\n",
    "\n",
    " # 주가 예측 -> test 데이터를 이용하여 학습된 LSTM모델을 테스트\n",
    " predictions = model.predict(X_test)\n",
    "\n",
    " # 실제값 변환\n",
    " # 실제값으로 변화시키기 위해서 기존 데이터에서 종가의 최댓값과 최솟값을 가져옵니다\n",
    " close_min = csv_df['Close'].min()\n",
    " close_max = csv_df['Close'].max()\n",
    "\n",
    " print(csv_df['Close'].min())\n",
    " print(csv_df['Close'].max())\n",
    "\n",
    " # MinMaxScaler이용해서 실제값으로 역변환\n",
    " scaler2 = MinMaxScaler()\n",
    " scaled_df2 = scaler2.fit_transform(csv_df[['Close']])\n",
    "\n",
    " # MinMaxScaler에 정규화에 사용한 최솟값과 최댓값을 설정\n",
    " scaler2.data_min_ = close_min  # 정규화에 사용한 최솟값\n",
    " scaler2.data_max_ = close_max  # 정규화에 사용한 최댓값\n",
    "\n",
    " # 예측한 출력값을 실제값으로 역변환\n",
    " original_pred_values = scaler2.inverse_transform(predictions)\n",
    "\n",
    " # 실제로 에측하기\n",
    " # feature_df 에서 가장 최근의 값을 window_size 만큼 가져옴\n",
    " pred_feature = feature_df.tail(window_size)\n",
    "\n",
    " pred_feature_list = []\n",
    " pred_feature_list.append(pred_feature)\n",
    " pred_feature = np.array(pred_feature_list)\n",
    "\n",
    " # 10일 예측 -> 10일까지의 예측값 10개 출력\n",
    " predictions_10d = model.predict(pred_feature)\n",
    " pred_values_10d = scaler2.inverse_transform(predictions_10d)\n",
    "\n",
    " pred_values_5d = pred_values_5d.flatten().tolist()\n",
    " pred_values_10d = pred_values_10d.flatten().tolist()\n",
    "\n",
    " day_five[company] = pred_values_5d\n",
    " day_ten[company] = pred_values_10d\n",
    "\n",
    " print('5일 예측값', pred_values_5d)\n",
    " print('10일 예측값', pred_values_10d)\n",
    " print('/n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qDmpu8aRxVLD"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HIPJHm-Y0TjI",
    "outputId": "e24ff7b1-0cc0-4721-a0fa-7563a9b36ac9"
   },
   "outputs": [],
   "source": [
    "day_five"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ue85wW5H0W47",
    "outputId": "7cb3cad4-750b-4afc-8e11-56714cb4bf33"
   },
   "outputs": [],
   "source": [
    "day_ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CAeQrnUk0awu"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "data = {\n",
    "    'day_five': day_five,\n",
    "    'day_ten': day_ten\n",
    "}\n",
    "\n",
    "server_url = 'https://616d-39-118-146-59.ngrok-free.app/prediction'\n",
    "\n",
    "response = requests.post(server_url, json=data)  # POST 요청으로 변경, 헤더는 자동으로 설정됨\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print('성공')\n",
    "else:\n",
    "    print('실패:', response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNFZ3Rz/Y6LSARFIy2BBDO3",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "CapstonStockProject",
   "language": "python",
   "name": "capstonestockproject"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
